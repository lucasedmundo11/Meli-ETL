{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3e7d41",
   "metadata": {},
   "source": [
    "# Análise BigQuery - Mercado Libre (Samsung Galaxy S25)\n",
    "___\n",
    "\n",
    "### Notebook para responder as perguntas:\n",
    "1) ¿Hay algún vendedor con múltiples publicaciones? En caso de que si, ¿con cuantas?\n",
    "2) ¿Promedio de ventas por seller?\n",
    "3) ¿Cuál es el precio promedio en dólares?\n",
    "4) ¿Porcentaje de artículos con garantía?\n",
    "5) ¿Métodos de Shipping que ofrecen?\n",
    "\n",
    "### Instruções:\n",
    "- Ajuste PROJECT_ID, DATASET e TABLE abaixo (ou configure via variáveis de ambiente).\n",
    "- Garanta que a variável de ambiente GOOGLE_APPLICATION_CREDENTIALS esteja definida com a chave do service account.\n",
    "- Executar células sequencialmente.\n",
    "\n",
    "### Observações Adicionais:\n",
    "Nos últimos meses, a API do Mercado Livre passou por alterações relevantes que impactaram diretamente o acesso a dados anteriormente públicos. Endpoints como /search e /items, antes amplamente acessíveis, passaram a exigir autenticação e, adicionalmente, foram limitados para retorno apenas de itens próprios, impossibilitando a consulta aberta a anúncios de terceiros. Essas mudanças inviabilizaram a extração completa das informações necessárias para o case exclusivamente via API oficial.\n",
    "\n",
    "Diante desse cenário, foi necessário recorrer a alternativas para concluir o desafio. Considerando que o uso direto de scraping e crawling é bloqueado pelos mecanismos de segurança e privacidade do MeLi — demandando infraestrutura adicional com proxies e rotação de IPs — optou-se pelo uso de clientes de API especializados em scraping, viabilizando o acesso aos dados dentro do tempo disponível.\n",
    "\n",
    "Portanto, houve diferença quanto aos retornos esperados, uma vez que alterou-se a API de origem, resultando na ausência de informações como métodos de envio disponíveis e produtos sob garantia, impactando as respostas das questões 4 e 5. Entretanto, a fim de demonstrar os conhecimentos necessários, elaborei cenários hipotéticos simulando a presença dessas colunas e apresentei como as trataria em código.\n",
    "\n",
    "Essa abordagem permitiu a execução plena do case, respeitando os limites técnicos e prazos estabelecidos, ao mesmo tempo em que garantiu a demonstração das capacidades técnicas esperadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e51cd525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando tabela: `meli-etl-476805.mercado_libre.products_samsung_s25`\n"
     ]
    }
   ],
   "source": [
    "# Configuração inicial\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "\n",
    "# Ajuste estes valores conforme seu projeto/dataset/tabela\n",
    "PROJECT_ID = os.getenv(\"GCP_PROJECT_ID\", \"seu-projeto-gcp\")\n",
    "DATASET = os.getenv(\"BQ_DATASET\", \"mercado_libre\")\n",
    "TABLE = os.getenv(\"BQ_TABLE\", \"products_samsung_s25\")\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../../meli-etl-key.json\"\n",
    "\n",
    "BQ_TABLE = f\"`{PROJECT_ID}.{DATASET}.{TABLE}`\"\n",
    "\n",
    "print(\"Usando tabela:\", BQ_TABLE)\n",
    "\n",
    "# Inicializar cliente BigQuery\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Helper: executar query e retornar DataFrame\n",
    "def run_query(sql: str, max_results: int = None) -> pd.DataFrame:\n",
    "    job = client.query(sql)\n",
    "    df = job.result().to_dataframe(create_bqstorage_client=True, progress_bar_type=None)\n",
    "    if max_results is not None:\n",
    "        return df.head(max_results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd06618",
   "metadata": {},
   "source": [
    "### 1) ¿Hay algún vendedor con múltiples publicaciones? En caso de que si, ¿con cuantas?\n",
    " - Definimos \"publicación\" como uma linha/tabela entry.\n",
    " - Buscar sellers com COUNT(*) > 1, listar quantidade de publicações por seller,\n",
    "   e mostrar top sellers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b37151",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_sellers_multi = f\"\"\"\n",
    "SELECT\n",
    "  seller,\n",
    "  COUNT(1) AS listings_count\n",
    "FROM {BQ_TABLE}\n",
    "WHERE seller IS NOT NULL AND seller != '' AND condition = 'New'\n",
    "GROUP BY seller\n",
    "HAVING COUNT(1) > 1\n",
    "ORDER BY listings_count DESC\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "df_sellers_multi = run_query(sql_sellers_multi)\n",
    "print(\"Sellers com múltiplas publicações (top 10):\")\n",
    "display(df_sellers_multi.head(10))\n",
    "\n",
    "# Resumo: quantos sellers têm múltiplas publicações e totais\n",
    "sql_sellers_multi_summary = f\"\"\"\n",
    "WITH counts AS (\n",
    "  SELECT seller, COUNT(1) AS listings_count\n",
    "  FROM {BQ_TABLE}\n",
    "  WHERE seller IS NOT NULL AND seller != '' AND condition = 'New'\n",
    "  GROUP BY seller\n",
    ")\n",
    "SELECT\n",
    "  COUNT(1) AS sellers_with_multiple_listings,\n",
    "  SUM(listings_count) AS total_listings_of_these_sellers,\n",
    "  AVG(listings_count) AS avg_listings_per_seller_with_multiple\n",
    "FROM counts\n",
    "WHERE listings_count > 1\n",
    "\"\"\"\n",
    "df_sellers_multi_summary = run_query(sql_sellers_multi_summary)\n",
    "display(df_sellers_multi_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319de51b",
   "metadata": {},
   "source": [
    "### 2) ¿Promedio de ventas por seller?\n",
    "- Existem duas interpretações:\n",
    "\n",
    "  A) Promedio de \"sellCount\" por seller (média das vendas reportadas por cada publicação).\n",
    "\n",
    "  B) Promedio total de ventas por seller (soma de sellCount por seller, depois média entre sellers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Media de sellCount por listing (considerando apenas linhas com sellCount)\n",
    "sql_avg_sellcount_per_listing = f\"\"\"\n",
    "SELECT\n",
    "  AVG(sellCount) AS avg_sellcount_per_listing\n",
    "FROM {BQ_TABLE}\n",
    "WHERE sellCount IS NOT NULL AND condition = 'New'\n",
    "\"\"\"\n",
    "df_avg_a = run_query(sql_avg_sellcount_per_listing)\n",
    "display(df_avg_a)\n",
    "\n",
    "# B) Para cada seller, soma sellCount; depois média entre sellers (usando APPROX_QUANTILES pra mediana)\n",
    "sql_avg_total_sales_per_seller = f\"\"\"\n",
    "WITH seller_totals AS (\n",
    "  SELECT\n",
    "    seller,\n",
    "    SUM(COALESCE(sellCount, 0)) AS total_sold,\n",
    "    COUNT(1) AS listings\n",
    "  FROM {BQ_TABLE}\n",
    "  WHERE seller IS NOT NULL AND seller != '' AND condition = 'New'\n",
    "  GROUP BY seller\n",
    ")\n",
    "SELECT\n",
    "  COUNT(1) AS num_sellers,\n",
    "  AVG(total_sold) AS avg_total_sales_per_seller,\n",
    "  APPROX_QUANTILES(total_sold, 100)[OFFSET(50)] AS median_total_sales_per_seller\n",
    "FROM seller_totals;\n",
    "\"\"\"\n",
    "df_avg_b = run_query(sql_avg_total_sales_per_seller)\n",
    "display(df_avg_b)\n",
    "\n",
    "# Se quiser ver top sellers por total_sold:\n",
    "sql_top_sellers = f\"\"\"\n",
    "SELECT seller, SUM(COALESCE(sellCount,0)) AS total_sold, COUNT(1) AS listings\n",
    "FROM {BQ_TABLE}\n",
    "WHERE seller IS NOT NULL AND seller != '' AND condition = 'New'\n",
    "GROUP BY seller\n",
    "ORDER BY total_sold DESC\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "df_top_sellers = run_query(sql_top_sellers)\n",
    "print(\"Top sellers por vendas totais (top 10):\")\n",
    "display(df_top_sellers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa172ca7",
   "metadata": {},
   "source": [
    "### 3) ¿Cuál es el precio promedio en dólares?\n",
    "- A tabela contém 'price' (FLOAT) e 'currency' (STRING).\n",
    "- Estratégia:\n",
    "  * Se currency = 'USD' -> usa price direto.\n",
    "  * Se currency = 'ARS' -> converte usando taxa de câmbio ARS->USD.\n",
    "  * Outros currencies -> descartamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5abd89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo (amostra) - média convertida (USD): 1352.2851992680849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items_considered</th>\n",
       "      <th>avg_price_usd</th>\n",
       "      <th>median_price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>1352.285199</td>\n",
       "      <td>1276.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_items_considered  avg_price_usd  median_price_usd\n",
       "0                      47    1352.285199            1276.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ars_to_usd = 0.00069\n",
    "\n",
    "# Query que converte preços para USD (aplica apenas a currency 'ARS' e 'USD')\n",
    "sql_price_usd = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(1) AS total_items_considered,\n",
    "  AVG(CASE\n",
    "        WHEN currency = 'USD' THEN price\n",
    "        WHEN currency = 'ARS' THEN SAFE_DIVIDE(price, {1.0/ars_to_usd if ars_to_usd != 0 else 1})\n",
    "        -- Note: SAFE_DIVIDE used in case of issues; here we compute price in USD by dividing by (ARS per USD).\n",
    "        ELSE NULL\n",
    "      END) AS avg_price_usd,\n",
    "  PERCENTILE_CONT(CASE\n",
    "        WHEN currency = 'USD' THEN price\n",
    "        WHEN currency = 'ARS' THEN SAFE_DIVIDE(price, {1.0/ars_to_usd if ars_to_usd != 0 else 1})\n",
    "        ELSE NULL\n",
    "      END, 0.5) OVER() AS median_price_usd\n",
    "FROM {BQ_TABLE}\n",
    "WHERE price IS NOT NULL AND currency IS NOT NULL  AND condition = 'New'\n",
    "\"\"\"\n",
    "# Observação: a formula acima usa 1/(ARS->USD) para converter; se ARS->USD = 0.005 (1 ARS = 0.005 USD),\n",
    "# então price_in_usd = price * 0.005. Para manter legível, definimos denom = 1/(rate) quando queríamos dividir.\n",
    "# Para evitar confusão, vamos calcular no pandas em seguida com taxa correta.\n",
    "\n",
    "df_price_sample = run_query(f\"\"\"\n",
    "SELECT price, currency FROM {BQ_TABLE} WHERE price IS NOT NULL  AND condition = 'New' LIMIT 1000\n",
    "\"\"\", max_results=1000)\n",
    "# Converter em pandas para aplicar taxa de forma explícita\n",
    "def convert_price_to_usd(row, rate):\n",
    "    try:\n",
    "        if row[\"currency\"] == \"USD\":\n",
    "            return float(row[\"price\"])\n",
    "        if row[\"currency\"] == \"ARS\":\n",
    "            # rate = 1 ARS = rate USD\n",
    "            return float(row[\"price\"]) * rate\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df_price_sample[\"price_usd\"] = df_price_sample.apply(lambda r: convert_price_to_usd(r, ars_to_usd), axis=1)\n",
    "# Calcular média com pandas usando amostra (para demonstrar)\n",
    "print(\"Exemplo (amostra) - média convertida (USD):\", df_price_sample[\"price_usd\"].dropna().mean())\n",
    "\n",
    "# Para cálculo robusto em BigQuery (aplicando rate): vamos usar rate como multiplicador (price * rate when ARS)\n",
    "rate = ars_to_usd\n",
    "sql_price_usd_bq = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(1) AS total_items_considered,\n",
    "  AVG(CASE\n",
    "        WHEN currency = 'USD' THEN price\n",
    "        WHEN currency = 'ARS' THEN price * {rate}\n",
    "        ELSE NULL\n",
    "      END) AS avg_price_usd,\n",
    "  APPROX_QUANTILES(CASE\n",
    "        WHEN currency = 'USD' THEN price\n",
    "        WHEN currency = 'ARS' THEN price * {rate}\n",
    "        ELSE NULL\n",
    "      END, 100)[OFFSET(50)] AS median_price_usd\n",
    "FROM {BQ_TABLE}\n",
    "WHERE price IS NOT NULL AND currency IN ('USD','ARS') AND condition = 'New'\n",
    "\"\"\"\n",
    "df_price_usd_bq = run_query(sql_price_usd_bq)\n",
    "display(df_price_usd_bq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d9cce",
   "metadata": {},
   "source": [
    "### 4) ¿Porcentaje de artículos con garantía?\n",
    "- Considerando o campo `warranty` (STRING), que o item tem garantia se `warranty` não é nulo e não é vazio.\n",
    "- Calculo percentagem sobre total de registros com informação de warranty (ou sobre total de rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88888be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_warranty_pct = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(1) AS total_items,\n",
    "  SUM(CASE WHEN warranty IS NOT NULL AND TRIM(warranty) <> '' THEN 1 ELSE 0 END) AS items_with_warranty,\n",
    "  SAFE_DIVIDE(SUM(CASE WHEN warranty IS NOT NULL AND TRIM(warranty) <> '' THEN 1 ELSE 0 END), COUNT(1)) AS pct_with_warranty\n",
    "FROM {BQ_TABLE}\n",
    "\"\"\"\n",
    "#df_warranty = run_query(sql_warranty_pct)\n",
    "# formatar percent\n",
    "#df_warranty[\"pct_with_warranty_percent\"] = df_warranty[\"pct_with_warranty\"] * 100\n",
    "#display(df_warranty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59332c5",
   "metadata": {},
   "source": [
    "### 5) ¿Métodos de Shipping que ofrecen?\n",
    "- Considerando verificar possíveis campos que contenham a palavra 'ship' ou 'envio'.\n",
    "- Se não houver coluna explícita, procurar na coluna `description` por termos comuns (MercadoEnvíos, envío, retiro, envío gratis, pickup, \"full\").\n",
    "- Em seguida agrupar e contar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a) listar colunas para conferir se existe campo relacionado a shipping\n",
    "table = client.get_table(f\"{PROJECT_ID}.{DATASET}.{TABLE}\")\n",
    "print(\"Colunas da tabela:\", [f.name for f in table.schema])\n",
    "\n",
    "# 5b) Se houver coluna 'shipping' ou similar, mostrar distinct\n",
    "shipping_like_cols = [c.name for c in table.schema if any(k in c.name.lower() for k in (\"ship\", \"envio\", \"shipping\", \"shipment\"))]\n",
    "print(\"Colunas com nome relacionado a shipping:\", shipping_like_cols)\n",
    "\n",
    "if shipping_like_cols:\n",
    "    for col in shipping_like_cols:\n",
    "        sql_shipping_col = f\"\"\"\n",
    "        SELECT {col} AS shipping_value, COUNT(1) AS cnt\n",
    "        FROM {BQ_TABLE}\n",
    "        GROUP BY {col}\n",
    "        ORDER BY cnt DESC\n",
    "        LIMIT 100\n",
    "        \"\"\"\n",
    "        df_shipping_col = run_query(sql_shipping_col)\n",
    "        print(f\"Distinct values for {col}:\")\n",
    "        display(df_shipping_col)\n",
    "else:\n",
    "    print(\"Nenhuma coluna explícita relacionada a shipping encontrada. Buscando por keywords na descrição...\")\n",
    "\n",
    "# Buscar keywords na descrição\n",
    "keywords = [\"envio\", \"envío\", \"mercadoenvíos\", \"mercadoenvios\", \"envío gratis\", \"retiro\", \"retiro en\", \"envío gratis\", \"mercadoenvios full\", \"full\", \"shipping\", \"pickup\", \"envio gratis\"]\n",
    "# Construir expressão REGEXP_CONTAINS ORs\n",
    "regex_expr = \"|\".join([kw.replace(\"'\", \"\\\\'\") for kw in keywords])\n",
    "sql_search_shipping = f\"\"\"\n",
    "SELECT\n",
    "  CASE\n",
    "    WHEN REGEXP_CONTAINS(LOWER(COALESCE(description,'')), r'({regex_expr})') THEN 'mentions_shipping_keywords'\n",
    "    ELSE 'no_keywords'\n",
    "  END AS shipping_kw,\n",
    "  COUNT(1) as cnt\n",
    "FROM {BQ_TABLE}\n",
    "GROUP BY shipping_kw\n",
    "\"\"\"\n",
    "df_shipping_kw = run_query(sql_search_shipping)\n",
    "display(df_shipping_kw)\n",
    "\n",
    "# Para extrair snippets e estimar métodos mais usados, buscar frases contendo keywords\n",
    "sql_snippets = f\"\"\"\n",
    "SELECT\n",
    "  description,\n",
    "  url,\n",
    "  seller,\n",
    "  REGEXP_EXTRACT(LOWER(COALESCE(description, '')), r'(env[ií]o[s]?\\\\s+gratis|retiro\\\\s+en\\\\s+[a-z0-9\\\\s]+|mercadoenv[ií]os|full|shipping|pickup)') AS snippet\n",
    "FROM {BQ_TABLE}\n",
    "WHERE REGEXP_CONTAINS(LOWER(COALESCE(description, '')), r'({regex_expr})')\n",
    "LIMIT 200\n",
    "\"\"\"\n",
    "#df_snippets = run_query(sql_snippets)\n",
    "#print(\"Exemplos de snippets onde aparecem referências a shipping (até 200 amostras):\")\n",
    "#display(df_snippets.head(50))\n",
    "\n",
    "## Agrupar por snippet para ver métodos frequentes\n",
    "#df_snippets[\"snippet_clean\"] = df_snippets[\"snippet\"].fillna(\"\").str.strip()\n",
    "#shipping_summary = df_snippets[\"snippet_clean\"].value_counts().reset_index()\n",
    "#shipping_summary.columns = [\"snippet\", \"count\"]\n",
    "#display(shipping_summary.head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
